trigger: none
pr: none

parameters:
  - name: env
    displayName: Environment
    type: string
    default: nonprod
    values: [nonprod, prod]

  - name: destroy
    displayName: Destroy
    type: boolean
    default: false

variables:
  TF_DIR: '.' 
  TF_VAR_FILE: '${{ parameters.env }}.tfvars'
  AWS_SERVICE_CONNECTION: bahi-aws  
  AWS_REGION: us-east-1

pool:
  vmImage: ubuntu-latest

steps:
- checkout: self

- task: TerraformInstaller@1
  displayName: Install Terraform
  inputs:
    terraformVersion: latest

# 1. Terraform Init
- task: AWSShellScript@1
  displayName: Terraform init
  inputs:
    awsCredentials: $(AWS_SERVICE_CONNECTION)
    regionName: $(AWS_REGION)
    scriptType: inline
    inlineScript: |
      set -euo pipefail
      cd "$(TF_DIR)"
      terraform init

# 2. Terraform Plan
- task: AWSShellScript@1
  displayName: Terraform plan
  inputs:
    awsCredentials: $(AWS_SERVICE_CONNECTION)
    regionName: $(AWS_REGION)
    scriptType: inline
    inlineScript: |
      set -euo pipefail
      cd "$(TF_DIR)"
      
      echo "Running plan for Environment: ${{ parameters.env }}"
      
      if [ "${{ parameters.destroy }}" = "True" ]; then
        echo "Creating DESTROY plan..."
        terraform plan -destroy -out=tfplan -var-file="$(TF_VAR_FILE)"
      else
        echo "Creating APPLY plan..."
        terraform plan -out=tfplan -var-file="$(TF_VAR_FILE)"
      fi

# 3. Terraform Apply
- task: AWSShellScript@1
  displayName: Terraform apply
  inputs:
    awsCredentials: $(AWS_SERVICE_CONNECTION)
    regionName: $(AWS_REGION)
    scriptType: inline
    inlineScript: |
      set -euo pipefail
      cd "$(TF_DIR)"
      
      echo "Applying tfplan..."
      terraform apply -auto-approve tfplan

# 4. Install Tools (Kubectl, Helm)
- task: KubectlInstaller@0
  displayName: Install kubectl
  inputs:
    kubectlVersion: 'latest'

- task: HelmInstaller@1
  displayName: Install Helm
  inputs:
    helmVersionToInstall: 'latest'

# 5. Configure Kubeconfig
- task: AWSShellScript@1
  displayName: Configure kubeconfig
  condition: and(succeeded(), ne('${{ parameters.destroy }}','True'))
  inputs:
    awsCredentials: $(AWS_SERVICE_CONNECTION)
    regionName: $(AWS_REGION)
    scriptType: inline
    inlineScript: |
      set -euo pipefail
      cd "$(TF_DIR)"
      
      # Get Cluster Name from Terraform Output
      CLUSTER_NAME="$(terraform output -raw cluster_name)"
      
      echo "Updating kubeconfig for cluster: $CLUSTER_NAME in region $(AWS_REGION)..."
      aws eks update-kubeconfig --name "$CLUSTER_NAME" --region "$(AWS_REGION)"
      
      kubectl get nodes

# 6. Create Namespaces
- task: AWSShellScript@1
  displayName: Create namespaces
  condition: and(succeeded(), ne('${{ parameters.destroy }}','True'))
  inputs:
    awsCredentials: $(AWS_SERVICE_CONNECTION)
    regionName: $(AWS_REGION)
    scriptType: inline
    inlineScript: |
      set -euo pipefail
      echo "Creating namespaces..."
      kubectl create namespace ingress-nginx --dry-run=client -o yaml | kubectl apply -f -
      kubectl create namespace nexus --dry-run=client -o yaml | kubectl apply -f -
      kubectl create namespace sonarqube --dry-run=client -o yaml | kubectl apply -f -
      kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -

# 7. Helm Installs (Using Plugins with 15m timeout)
- task: HelmDeploy@0
  displayName: Install Nexus
  condition: and(succeeded(), ne('${{ parameters.destroy }}','True'))
  inputs:
    connectionType: None
    command: upgrade
    chartType: Name
    chartName: sonatype/nexus-repository-manager
    releaseName: nexus
    namespace: nexus
    install: true
    arguments: '--repo https://sonatype.github.io/helm3-charts/ --wait --timeout 15m --atomic --cleanup-on-fail'

- task: HelmDeploy@0
  displayName: Install SonarQube
  condition: and(succeeded(), ne('${{ parameters.destroy }}','True'))
  inputs:
    connectionType: None
    command: upgrade
    chartType: Name
    chartName: sonarqube/sonarqube
    releaseName: sonarqube
    namespace: sonarqube
    install: true
    arguments: '--repo https://SonarSource.github.io/helm-chart-sonarqube --wait --timeout 15m --atomic --cleanup-on-fail'

- task: HelmDeploy@0
  displayName: Install Argo CD
  condition: and(succeeded(), ne('${{ parameters.destroy }}','True'))
  inputs:
    connectionType: None
    command: upgrade
    chartType: Name
    chartName: argo-cd
    releaseName: argocd
    namespace: argocd
    install: true
    arguments: '--repo https://argoproj.github.io/argo-helm --wait --timeout 15m --atomic --cleanup-on-fail'

# 8. Verification
- task: AWSShellScript@1
  displayName: Verify platform services
  condition: and(succeeded(), ne('${{ parameters.destroy }}','True'))
  inputs:
    awsCredentials: $(AWS_SERVICE_CONNECTION)
    regionName: $(AWS_REGION)
    scriptType: inline
    inlineScript: |
      set -euo pipefail
      echo "Retrieving pod status..."
      echo "--- Ingress Nginx ---"
      kubectl get pods -n ingress-nginx
      echo "--- Nexus ---"
      kubectl get pods -n nexus
      echo "--- SonarQube ---"
      kubectl get pods -n sonarqube
      echo "--- ArgoCD ---"
      kubectl get pods -n argocd